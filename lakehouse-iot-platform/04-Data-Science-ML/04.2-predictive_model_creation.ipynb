{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "796dbd51-d7e2-4efd-8b98-fa0fe6ae863e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&nbsp;\n",
    "&nbsp;\n",
    "![](../_resources/images/e2eai-4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "fff79d53-904b-42c3-96ef-1e22969cbd3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Data Science with Databricks\n",
    "\n",
    "## ML is key to wind turbine farm optimization\n",
    "\n",
    "The current market makes energy even more strategic than before. Being able to ingest and analyze our Wind turbine state is a first step, but this isn't enough to thrive in a very competitive market.\n",
    "\n",
    "We need to go further to optimize our energy production, reduce maintenance cost and reduce downtime. Modern data company achieve this with AI.\n",
    "\n",
    "<style>\n",
    ".right_box{\n",
    "  margin: 30px; box-shadow: 10px -10px #CCC; width:650px;height:300px; background-color: #1b3139ff; box-shadow:  0 0 10px  rgba(0,0,0,0.6);\n",
    "  border-radius:25px;font-size: 35px; float: left; padding: 20px; color: #f9f7f4; }\n",
    ".badge {\n",
    "  clear: left; float: left; height: 30px; width: 30px;  display: table-cell; vertical-align: middle; border-radius: 50%; background: #fcba33ff; text-align: center; color: white; margin-right: 10px}\n",
    ".badge_b { \n",
    "  height: 35px}\n",
    "</style>\n",
    "<link href='https://fonts.googleapis.com/css?family=DM Sans' rel='stylesheet'>\n",
    "<div style=\"font-family: 'DM Sans'; display: flex; align-items: flex-start;\">\n",
    "  <!-- Left Section -->\n",
    "  <div style=\"width: 50%; color: #1b3139; padding-right: 20px;\">\n",
    "    <div style=\"color: #ff5f46; font-size:80px;\">90%</div>\n",
    "    <div style=\"font-size:30px; margin-top: -20px; line-height: 30px;\">\n",
    "      Enterprise applications will be AI-augmented by 2025 —IDC\n",
    "    </div>\n",
    "    <div style=\"color: #ff5f46; font-size:80px;\">$10T+</div>\n",
    "    <div style=\"font-size:30px; margin-top: -20px; line-height: 30px;\">\n",
    "       Projected business value creation by AI in 2030 —PWC\n",
    "    </div>\n",
    "  </div>\n",
    "\n",
    "  <!-- Right Section -->\n",
    "  <div class=\"right_box\", style=\"width: 50%; color: red; font-size: 30px; line-height: 1.5; padding-left: 20px;\">\n",
    "    But—huge challenges getting ML to work at scale!<br/><br/>\n",
    "    In fact, most ML projects still fail before getting to production\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "## Machine learning is data + transforms.\n",
    "\n",
    "ML is hard because delivering value to business lines isn't only about building a Model. <br>\n",
    "The ML lifecycle is made of data pipelines: Data-preprocessing, feature engineering, training, inference, monitoring and retraining...<br>\n",
    "Stepping back, all pipelines are data + code.\n",
    "\n",
    "\n",
    "<img style=\"float: right; margin-top: 10px\" width=\"500px\" src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/refs/heads/main/images/manufacturing/lakehouse-iot-turbine/team_flow_marc.png\" />\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/refs/heads/main/images/marc.png\" style=\"float: left;\" width=\"80px\"> \n",
    "<h3 style=\"padding: 10px 0px 0px 5px\">Marc, as a Data Scientist, needs a data + ML platform accelerating all the ML & DS steps:</h3>\n",
    "\n",
    "<div style=\"font-size: 19px; margin-left: 73px; clear: left\">\n",
    "<div class=\"badge_b\"><div class=\"badge\">1</div> Build Data Pipeline</div>\n",
    "<div class=\"badge_b\"><div class=\"badge\">2</div> Data Exploration</div>\n",
    "<div class=\"badge_b\"><div class=\"badge\">3</div> Feature creation</div>\n",
    "<div class=\"badge_b\"><div class=\"badge\">4</div> Build & train model</div>\n",
    "<div class=\"badge_b\"><div class=\"badge\">5</div> Deploy Model (Batch or serverless realtime)</div>\n",
    "<div class=\"badge_b\"><div class=\"badge\">6</div> Monitoring</div>\n",
    "</div>\n",
    "\n",
    "**Marc needs a Data Intelligence Platform**. Let's see how we can deploy a Predictive Maintenance model in production with Databricks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "035b2c73-69a2-4668-af0f-9c61370a10a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Predictive maintenance\n",
    "\n",
    "Let's see how we can now leverage the sensor data to build a model predictive maintenance model.\n",
    "\n",
    "Our first step as Data Scientist is to analyze and build the features we'll use to train our model.\n",
    "\n",
    "The sensor table enriched with turbine data has been saved within our Delta Live Table pipeline. All we have to do is read this information, analyze it and create an ML model.\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/raw/main/images/manufacturing/lakehouse-iot-turbine/lakehouse-manuf-iot-ds-flow.png\" width=\"1000px\">\n",
    "\n",
    "\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=lakehouse&org_id=4003492105941350&notebook=%2F04-Data-Science-ML%2F04.1-automl-iot-turbine-predictive-maintenance&demo_name=lakehouse-iot-platform&event=VIEW&path=%2F_dbdemos%2Flakehouse%2Flakehouse-iot-platform%2F04-Data-Science-ML%2F04.1-automl-iot-turbine-predictive-maintenance&version=1\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6be02e7b-2438-4986-95e3-2d4c8c68a12b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --quiet databricks-sdk==0.40.0 mlflow==2.22.0 optuna optuna-integration[mlflow] xgboost\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbca96a8-dd37-43ae-88b3-1202b9bc77a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run ../_resources/00-setup $reset_all_data=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f0410a6-bf3e-41e8-979b-b07425dde7bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.deployments import get_deploy_client\n",
    "import optuna\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "import os\n",
    "import requests\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "3c8305a2-5b76-49f1-ae8d-ad13c436e3b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Accelerating Predictive maintenance model creation using MLFlow in Databricks\n",
    "\n",
    "MLflow is an open source project allowing model tracking, packaging and deployment. Everytime your datascientist team work on a model, Databricks will track all the parameter and data used and will save it. This ensure ML traceability and reproductibility, making it easy to know which model was build using which parameters/data.\n",
    "\n",
    "### A glass-box solution that empowers data teams without taking away control\n",
    "\n",
    "While Databricks simplify model deployment and governance (MLOps) with MLFlow, bootstraping new ML projects can still be long and inefficient. \n",
    "\n",
    "\n",
    "<img width=\"1000\" src=\"https://github.com/QuentinAmbard/databricks-demo/raw/main/retail/resources/images/auto-ml-full.png\"/>\n",
    "\n",
    "\n",
    "Models can be directly deployed, or instead leverage generated notebooks to boostrap projects with best-practices, saving you weeks of efforts.\n",
    "\n",
    "<br style=\"clear: both\">\n",
    "\n",
    "<img width=\"600\" src=\"https://github.com/QuentinAmbard/databricks-demo/raw/main/retail/resources/images/churn-auto-ml.png\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f127e71-d271-4c54-93c3-a8487dafe0e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri('databricks-uc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0480eb80-fdee-4b76-b0c4-5ca2fcd5dbda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create Train / Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3184677c-828e-4d27-9fcd-3cf671d80d50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "features_table_name=f'{catalog}.{db}.turbine_hourly_features'\n",
    "\n",
    "# Read training dataset from catalog\n",
    "training_dataset = spark.table(features_table_name).drop('turbine_id')\n",
    "\n",
    "# Prepare features and labels\n",
    "X = training_dataset.toPandas()[['avg_energy', 'std_sensor_A', 'std_sensor_B', 'std_sensor_C', 'std_sensor_D', 'std_sensor_E', 'std_sensor_F']]\n",
    "\n",
    "y = training_dataset.toPandas()['abnormal_sensor']\n",
    "\n",
    "# Encode labels\n",
    "y_encoded = pd.factorize(y)[0]\n",
    "\n",
    "# Split the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y_encoded,\n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d68cc5c-19aa-437e-b9c8-75887cb025a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Save the signature (an example of the model input)\n",
    "signature = infer_signature(X_train, y_train)\n",
    "signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e6c59c1-4d3b-453c-acb0-d8d589292192",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# This ensures column names are included\n",
    "input_example = X_train.iloc[[0]]  # Picks first row, keeps column names!\n",
    "input_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41bd3e1e-e912-4c91-9584-d97efafd111f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Build Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a7adcad-84f7-4cc2-a20e-2c5f13de9f42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ML model versions in UC must have a model signature (Or input example). If you want to set a signature on a model that's already logged or saved, the mlflow.models.set_signature() API is available for this purpose.\n",
    "\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=\"Logistic Regression Run\"):\n",
    "\n",
    "    # Define and train the model\n",
    "    lr_model = LogisticRegression(max_iter=200)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    # Predict and evaluate\n",
    "    predictions = lr_model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions, average=\"macro\")\n",
    "    recall = recall_score(y_test, predictions, average=\"macro\")\n",
    "    f1 = f1_score(y_test, predictions, average=\"macro\")\n",
    "\n",
    "    # Log model parameters\n",
    "    mlflow.set_tag(\"model_family\", \"LogisticRegression\")\n",
    "    mlflow.log_param(\"max_iter\", 200)\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(lr_model, \n",
    "                            artifact_path=\"logreg_model\",\n",
    "                            input_example=input_example,\n",
    "                            signature=signature,\n",
    "                            #  registered_model_name=\"main.dbdemos_iot_turbine.dbdemos_turbine_maintenance\"\n",
    "                            )\n",
    "\n",
    "    print(f\"Logged with accuracy: {acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56fa11e8-b2e5-4132-bde3-57fce41267e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Build XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c19529a-8ddb-43c0-ab3e-bf6bbb031111",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=\"XGBoost Run\"):\n",
    "\n",
    "    # Define and train the model\n",
    "    xgb_model = XGBClassifier(\n",
    "        objective=\"multi:softprob\",\n",
    "        num_class=3,\n",
    "        max_depth=3,\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric=\"mlogloss\"\n",
    "    )\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    # Predict and evaluate\n",
    "    predictions = xgb_model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions, average=\"macro\")\n",
    "    recall = recall_score(y_test, predictions, average=\"macro\")\n",
    "    f1 = f1_score(y_test, predictions, average=\"macro\")\n",
    "\n",
    "    # Log model parameters\n",
    "    mlflow.set_tag(\"model_family\", \"XGBOOST\")\n",
    "    mlflow.log_param(\"max_depth\", 3)\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"learning_rate\", 0.1)\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "    mlflow.xgboost.log_model(xgb_model, \n",
    "                             artifact_path=\"xgb_model\",\n",
    "                             input_example=input_example,\n",
    "                             signature=signature,\n",
    "                             )\n",
    "    print(f\"Logged with accuracy: {acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ff8ff66-3111-4147-a0f6-c8ad883dc5cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Compare ML models to find best performing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cac711a-a32d-474f-919d-6d9f29fcffc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.search_runs(order_by=['metrics.accuracy DESC','start_time DESC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "097ad96e-6a02-4796-946a-81a4581223bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "best_run = mlflow.search_runs(order_by=['metrics.accuracy DESC','start_time DESC']).iloc[0]\n",
    "\n",
    "print(f\"Best accuracy:                   {best_run['metrics.accuracy']}\")\n",
    "print(f\"Best model type:                 {best_run['tags.model_family']}\")\n",
    "\n",
    "best_model_run_id = best_run['run_id']\n",
    "\n",
    "print(f\"Best model run id:               {best_model_run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6cdd75d-a555-4f66-bb59-6ff8610c6130",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Optimize our best performing model\n",
    "In a real world scenaio, we would start by comparing various model types, then tune hyperparameters for the best performing model type.  For this demo, we have only compared two model types: a logistic regression model to an XGBoost Classifier.\n",
    "\n",
    "To illustrate an optimization process, let's use [Optuna](https://optuna.org/) to tune our XGBoost model.\n",
    "\n",
    "Optuna is an open-source hyperparameter optimization framework for machine learning and deep learning models. It automates the process of finding the optimal hyperparameters for a given model and dataset, which can significantly improve model performance and reduce the manual effort involved in hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "049c1c58-ddfd-41fe-b238-59ae7e37b2bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set the mlflow experiment\n",
    "client = MlflowClient()\n",
    "experiments = client.search_experiments()\n",
    "notebook_name = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get().split(\"/\")[-1]\n",
    "\n",
    "# By default, the MLflow experiment name will be the notebook name\n",
    "cnt = 0\n",
    "for exp in experiments:\n",
    "    if notebook_name in exp.name:\n",
    "        print(f\"Experiment Name: {exp.name}, Experiment ID: {exp.experiment_id}\\n\")\n",
    "        cnt = cnt+1\n",
    "        experiment_id = exp.experiment_id\n",
    "if cnt > 1:\n",
    "    print(\"Multiple experiments found. Please delete the other experiment manually.\")\n",
    "elif cnt == 1:\n",
    "    print(f\"Using experiment {experiment_id}\")\n",
    "    mlflow.set_experiment(experiment_id=experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60ee3f66-9edc-4765-a8b2-8398200821a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate the MLflow callback for logging Optuna runs to MLflow\n",
    "mlflow_callback = MLflowCallback(\n",
    "    tracking_uri='databricks',\n",
    "    metric_name=\"accuracy\",\n",
    "    create_experiment=False,\n",
    "    mlflow_kwargs={\"nested\": True},\n",
    "    tag_trial_user_attrs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "326396af-19f5-4019-b404-ee934bfc7343",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"Define the objective function for hyperparameter tuning.\"\"\"\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "        # Invoke suggest methods of a Trial object to generate hyperparameters\n",
    "        cl_num_class = trial.suggest_int('num_class', 2, 10)\n",
    "        cl_max_depth = trial.suggest_int('max_depth', 2, 15)\n",
    "        cl_n_estimators = trial.suggest_int('n_estimators', 10, 100)\n",
    "\n",
    "        # Define our model, referencing the hyperparameters we just generated\n",
    "        classifier_obj = XGBClassifier(\n",
    "            objective=\"multi:softprob\",\n",
    "            num_class=cl_num_class,\n",
    "            max_depth=cl_max_depth,\n",
    "            n_estimators=cl_n_estimators,\n",
    "            learning_rate=0.1,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric=\"mlogloss\"\n",
    "        )\n",
    "        classifier_obj.fit(X_train, y_train)\n",
    "        y_pred = classifier_obj.predict(X_test)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "        recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "        f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "        # Log model parameters\n",
    "        mlflow.set_tag(\"model_family\", \"XGBOOST\")\n",
    "        mlflow.log_param(\"num_class\", cl_num_class)\n",
    "        mlflow.log_param(\"max_depth\", cl_max_depth)\n",
    "        mlflow.log_param(\"n_estimators\", cl_n_estimators)\n",
    "        mlflow.log_param(\"learning_rate\", 0.1)\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "    return acc  # An objective value linked with the Trial object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5df1c0df-a592-41a8-8235-f7c4cd48600f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run the optimize trials\n",
    "run_name = \"optimize\"\n",
    "\n",
    "# Initiate the parent run and call the hyperparameter tuning child run logic\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name=run_name, nested=True):\n",
    "  # Initialize the Optuna study\n",
    "  # Our goal is to maximize the accuracy (as defined in our objective function)\n",
    "  study = optuna.create_study(direction=\"maximize\", load_if_exists=True)\n",
    "\n",
    "  # Execute the hyperparameter optimization trials.\n",
    "  study.optimize(objective, n_trials=10, callbacks=[mlflow_callback])\n",
    "\n",
    "  mlflow.log_params(study.best_params)\n",
    "  mlflow.log_metric(\"accuracy\", study.best_value)\n",
    "\n",
    "  # Log tags\n",
    "  mlflow.set_tags(\n",
    "      tags={\n",
    "          \"project\": \"Turbine maintenance predictor\",\n",
    "          \"optimizer_engine\": \"optuna\",\n",
    "          \"model_family\": \"XGBOOST\",\n",
    "          \"feature_set_version\": 1,\n",
    "      }\n",
    "  )\n",
    "\n",
    "  # Log a fit model instance\n",
    "  model = XGBClassifier(study.best_params).fit(X_train, y_train)\n",
    "  y_pred = model.predict(X_test)\n",
    "\n",
    "  precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "  recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "  f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "  mlflow.log_metric(\"precision\", precision)\n",
    "  mlflow.log_metric(\"recall\", recall)\n",
    "  mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "  mlflow.xgboost.log_model(\n",
    "    xgb_model=model,\n",
    "    artifact_path=\"xgb_model\",\n",
    "    input_example=input_example,\n",
    "    signature=signature,\n",
    "  )\n",
    "\n",
    "  # Get the logged model uri so that we can load it from the artifact store\n",
    "  #model_uri = mlflow.get_artifact_uri(\"xgb_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "973c5cd6-a1e9-4f24-9333-090d2dc05ac0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Show only runs with a logged model (our objective function did not save a model for every run) \n",
    "# and sort by accuracy\n",
    "mlflow.search_runs(filter_string=\"tags.\\\"mlflow.log-model.history\\\" !=''\", order_by=['metrics.accuracy DESC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60fb6b40-e6a3-448d-960c-e8468bda4eaa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Compare previous best_run to the best optimized run\n",
    "print(f\"Best previous accuracy:          {best_run['metrics.accuracy']}\")\n",
    "print(f\"Best previous run id:            {best_model_run_id}\")\n",
    "\n",
    "best_opt_run = mlflow.search_runs(filter_string=\"tags.\\\"mlflow.log-model.history\\\" !=''\", order_by=['metrics.accuracy DESC']).iloc[0]\n",
    "\n",
    "print(f\"Best optimized accuracy:         {best_opt_run['metrics.accuracy']}\")\n",
    "\n",
    "best_opt_run_id = best_opt_run['run_id']\n",
    "\n",
    "print(f\"Best optimized model run id:     {best_opt_run_id}\")\n",
    "\n",
    "if best_opt_run['metrics.accuracy'] > best_run['metrics.accuracy']:\n",
    "    print(\"The accuracy improved by running parameter tuning\")\n",
    "else:\n",
    "    print(\"The accuracy did not improve by running parameter tuning\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ba437d4-ca23-41b3-96c3-7b007da1deeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now, we can test the best model. See if it is working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3b70bd7-a174-45e8-9689-6431d3903cb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "best_model_uri = f\"runs:/{best_opt_run_id}/logreg_model\" if best_run['tags.model_family'] == \"LogisticRegression\" else f\"runs:/{best_opt_run_id}/xgb_model\"\n",
    "\n",
    "model_name = \"turbine_maintenance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19feab71-205d-49e5-9f1e-9e8bdc485fc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Make sure the model is loaded correctly from MLflow\n",
    "loaded_model = mlflow.pyfunc.load_model(best_model_uri)\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec702667-8ef7-41d2-9df2-3375d32a324d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb533bbd-8815-4150-bebd-87bebd53af76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now we are satisfied with the model, we can register it in Unity Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8f05f40-211b-4cbf-a584-56d1200f56a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "latest_model = mlflow.register_model(best_model_uri, f\"{catalog}.{db}.{model_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d276f063-05ad-4003-8e4f-d94735a6bc6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "If we're ready, we can move this model into Production stage in a click, or using the API. Let's register the model to Unity Catalog and move it to production.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44459c45-9d3c-43ca-8131-f95867ebe39c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Flag it as Production ready using UC Aliases\n",
    "MlflowClient().set_registered_model_alias(name=f\"{catalog}.{db}.{model_name}\", \n",
    "                                          alias=\"prod\", \n",
    "                                          version=latest_model.version)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8281987032933773,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "04.2-predictive_model_creation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
