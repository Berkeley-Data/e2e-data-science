{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "796dbd51-d7e2-4efd-8b98-fa0fe6ae863e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&nbsp;\n",
    "&nbsp;\n",
    "![](../_resources/images/e2e-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "fff79d53-904b-42c3-96ef-1e22969cbd3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Data Science with Databricks\n",
    "\n",
    "## ML is key to wind turbine farm optimization\n",
    "\n",
    "The current market makes energy even more strategic than before. Being able to ingest and analyze our Wind turbine state is a first step, but this isn't enough to thrive in a very competitive market.\n",
    "\n",
    "We need to go further to optimize our energy production, reduce maintenance cost and reduce downtime. Modern data company achieve this with AI.\n",
    "\n",
    "<style>\n",
    ".right_box{\n",
    "  margin: 30px; box-shadow: 10px -10px #CCC; width:650px;height:300px; background-color: #1b3139ff; box-shadow:  0 0 10px  rgba(0,0,0,0.6);\n",
    "  border-radius:25px;font-size: 35px; float: left; padding: 20px; color: #f9f7f4; }\n",
    ".badge {\n",
    "  clear: left; float: left; height: 30px; width: 30px;  display: table-cell; vertical-align: middle; border-radius: 50%; background: #fcba33ff; text-align: center; color: white; margin-right: 10px}\n",
    ".badge_b { \n",
    "  height: 35px}\n",
    "</style>\n",
    "<link href='https://fonts.googleapis.com/css?family=DM Sans' rel='stylesheet'>\n",
    "<div style=\"font-family: 'DM Sans'; display: flex; align-items: flex-start;\">\n",
    "  <!-- Left Section -->\n",
    "  <div style=\"width: 50%; color: #1b3139; padding-right: 20px;\">\n",
    "    <div style=\"color: #ff5f46; font-size:80px;\">90%</div>\n",
    "    <div style=\"font-size:30px; margin-top: -20px; line-height: 30px;\">\n",
    "      Enterprise applications will be AI-augmented by 2025 —IDC\n",
    "    </div>\n",
    "    <div style=\"color: #ff5f46; font-size:80px;\">$10T+</div>\n",
    "    <div style=\"font-size:30px; margin-top: -20px; line-height: 30px;\">\n",
    "       Projected business value creation by AI in 2030 —PWC\n",
    "    </div>\n",
    "  </div>\n",
    "\n",
    "  <!-- Right Section -->\n",
    "  <div class=\"right_box\", style=\"width: 50%; color: red; font-size: 30px; line-height: 1.5; padding-left: 20px;\">\n",
    "    But—huge challenges getting ML to work at scale!<br/><br/>\n",
    "    In fact, most ML projects still fail before getting to production\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "## Machine learning is data + transforms.\n",
    "\n",
    "ML is hard because delivering value to business lines isn't only about building a Model. <br>\n",
    "The ML lifecycle is made of data pipelines: Data-preprocessing, feature engineering, training, inference, monitoring and retraining...<br>\n",
    "Stepping back, all pipelines are data + code.\n",
    "\n",
    "\n",
    "<img style=\"float: right; margin-top: 10px\" width=\"500px\" src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/refs/heads/main/images/manufacturing/lakehouse-iot-turbine/team_flow_marc.png\" />\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/refs/heads/main/images/marc.png\" style=\"float: left;\" width=\"80px\"> \n",
    "<h3 style=\"padding: 10px 0px 0px 5px\">Marc, as a Data Scientist, needs a data + ML platform accelerating all the ML & DS steps:</h3>\n",
    "\n",
    "<div style=\"font-size: 19px; margin-left: 73px; clear: left\">\n",
    "<div class=\"badge_b\"><div class=\"badge\">1</div> Build Data Pipeline supporting real time (with DLT)</div>\n",
    "<div class=\"badge_b\"><div class=\"badge\">2</div> Data Exploration</div>\n",
    "<div class=\"badge_b\"><div class=\"badge\">3</div> Feature creation</div>\n",
    "<div class=\"badge_b\"><div class=\"badge\">4</div> Build & train model</div>\n",
    "<div class=\"badge_b\"><div class=\"badge\">5</div> Deploy Model (Batch or serverless realtime)</div>\n",
    "<div class=\"badge_b\"><div class=\"badge\">6</div> Monitoring</div>\n",
    "</div>\n",
    "\n",
    "**Marc needs a Data Intelligence Platform**. Let's see how we can deploy a Predictive Maintenance model in production with Databricks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "035b2c73-69a2-4668-af0f-9c61370a10a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Predictive maintenance\n",
    "\n",
    "Let's see how we can now leverage the sensor data to build a model predictive maintenance model.\n",
    "\n",
    "Our first step as Data Scientist is to analyze and build the features we'll use to train our model.\n",
    "\n",
    "The sensor table enriched with turbine data has been saved within our Delta Live Table pipeline. All we have to do is read this information, analyze it and create an ML model.\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/raw/main/images/manufacturing/lakehouse-iot-turbine/lakehouse-manuf-iot-ds-flow.png\" width=\"1000px\">\n",
    "\n",
    "*Note: Make sure you switched to the \"Machine Learning\" persona on the top left menu.*\n",
    "\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=lakehouse&org_id=4003492105941350&notebook=%2F04-Data-Science-ML%2F04.1-automl-iot-turbine-predictive-maintenance&demo_name=lakehouse-iot-platform&event=VIEW&path=%2F_dbdemos%2Flakehouse%2Flakehouse-iot-platform%2F04-Data-Science-ML%2F04.1-automl-iot-turbine-predictive-maintenance&version=1\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6be02e7b-2438-4986-95e3-2d4c8c68a12b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngrpcio-status 1.69.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\u001B[0m\u001B[31m\n\u001B[0m\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet databricks-sdk==0.40.0 databricks-feature-engineering==0.8.0 mlflow==2.22.0\n",
    "%pip install --quiet xgboost\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbca96a8-dd37-43ae-88b3-1202b9bc77a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "## Configuration file\n",
       "\n",
       "Please change your catalog and schema here to run the demo on a different catalog.\n",
       "\n",
       " \n",
       "<!-- Collect usage data (view). Remove it to disable collection. View README for more details.  -->\n",
       "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=lakehouse&org_id=4003492105941350&notebook=%2Fconfig&demo_name=lakehouse-iot-platform&event=VIEW&path=%2F_dbdemos%2Flakehouse%2Flakehouse-iot-platform%2Fconfig&version=1\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "\n",
       "# Technical Setup notebook. Hide this cell results\n",
       "Initialize dataset to the current user and cleanup data when reset_all_data is set to true\n",
       "\n",
       "Do not edit"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE CATALOG `main`\nusing catalog.database `main`.`dbdemos_iot_turbine`\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data already existing. Run with reset_all_data=true to force a data cleanup for your local demo.\n"
     ]
    }
   ],
   "source": [
    "%run ../_resources/00-setup $reset_all_data=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f0410a6-bf3e-41e8-979b-b07425dde7bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.deployments import get_deploy_client\n",
    "import os\n",
    "import requests\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "3c8305a2-5b76-49f1-ae8d-ad13c436e3b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Accelerating Predictive maintenance model creation using MLFlow in Databricks\n",
    "\n",
    "MLflow is an open source project allowing model tracking, packaging and deployment. Everytime your datascientist team work on a model, Databricks will track all the parameter and data used and will save it. This ensure ML traceability and reproductibility, making it easy to know which model was build using which parameters/data.\n",
    "\n",
    "### A glass-box solution that empowers data teams without taking away control\n",
    "\n",
    "While Databricks simplify model deployment and governance (MLOps) with MLFlow, bootstraping new ML projects can still be long and inefficient. \n",
    "\n",
    "\n",
    "<img width=\"1000\" src=\"https://github.com/QuentinAmbard/databricks-demo/raw/main/retail/resources/images/auto-ml-full.png\"/>\n",
    "\n",
    "\n",
    "Models can be directly deployed, or instead leverage generated notebooks to boostrap projects with best-practices, saving you weeks of efforts.\n",
    "\n",
    "<br style=\"clear: both\">\n",
    "\n",
    "<img width=\"600\" src=\"https://github.com/QuentinAmbard/databricks-demo/raw/main/retail/resources/images/churn-auto-ml.png\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f127e71-d271-4c54-93c3-a8487dafe0e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri('databricks-uc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3184677c-828e-4d27-9fcd-3cf671d80d50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "features_table_name=f'{catalog}.{db}.turbine_hourly_features'\n",
    "\n",
    "# read training dataset from catalog\n",
    "training_dataset = spark.table(features_table_name).drop('turbine_id')\n",
    "\n",
    "\n",
    "# 2. Prepare features and labels\n",
    "X = training_dataset.toPandas()[['avg_energy', 'std_sensor_A', 'std_sensor_B', 'std_sensor_C', 'std_sensor_D', 'std_sensor_E', 'std_sensor_F']]\n",
    "\n",
    "y = training_dataset.toPandas()['abnormal_sensor']\n",
    "\n",
    "# 3. Encode labels\n",
    "y_encoded = pd.factorize(y)[0]\n",
    "\n",
    "\n",
    "# Split the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y_encoded,\n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d68cc5c-19aa-437e-b9c8-75887cb025a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "inputs: \n",
       "  ['avg_energy': double (required), 'std_sensor_A': double (required), 'std_sensor_B': double (required), 'std_sensor_C': double (required), 'std_sensor_D': double (required), 'std_sensor_E': double (required), 'std_sensor_F': double (required)]\n",
       "outputs: \n",
       "  [Tensor('int64', (-1,))]\n",
       "params: \n",
       "  None"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from mlflow.models import infer_signature\n",
    "signature = infer_signature(X_train, y_train)\n",
    "signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e6c59c1-4d3b-453c-acb0-d8d589292192",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_energy</th>\n",
       "      <th>std_sensor_A</th>\n",
       "      <th>std_sensor_B</th>\n",
       "      <th>std_sensor_C</th>\n",
       "      <th>std_sensor_D</th>\n",
       "      <th>std_sensor_E</th>\n",
       "      <th>std_sensor_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2279</th>\n",
       "      <td>0.927237</td>\n",
       "      <td>1.100594</td>\n",
       "      <td>2.021509</td>\n",
       "      <td>3.124961</td>\n",
       "      <td>2.277981</td>\n",
       "      <td>3.052224</td>\n",
       "      <td>5.503263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      avg_energy  std_sensor_A  ...  std_sensor_E  std_sensor_F\n",
       "2279    0.927237      1.100594  ...      3.052224      5.503263\n",
       "\n",
       "[1 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# This ensures column names are included\n",
    "input_example = X_train.iloc[[0]]  # Picks first row, keeps column names!\n",
    "input_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a7adcad-84f7-4cc2-a20e-2c5f13de9f42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged with accuracy: 0.9693165969316597\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ML model versions in UC must have a model signature (Or input example). If you want to set a signature on a model that's already logged or saved, the mlflow.models.set_signature() API is available for this purpose.\n",
    "\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=\"Logistic Regression Run\"):\n",
    "\n",
    "    # Define and train the model\n",
    "    lr_model = LogisticRegression(max_iter=200)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    # Predict and evaluate\n",
    "    predictions = lr_model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions, average=\"macro\")\n",
    "    recall = recall_score(y_test, predictions, average=\"macro\")\n",
    "    f1 = f1_score(y_test, predictions, average=\"macro\")\n",
    "\n",
    "    # Log model parameters\n",
    "    mlflow.log_param(\"model_type\", \"LogisticRegression\")\n",
    "    mlflow.log_param(\"max_iter\", 200)\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(lr_model, \n",
    "                            artifact_path=\"logreg_model\",\n",
    "                            input_example=input_example,\n",
    "                            signature=signature,\n",
    "                            #  registered_model_name=\"main.dbdemos_iot_turbine.dbdemos_turbine_maintenance\"\n",
    "                            )\n",
    "\n",
    "    print(f\"Logged with accuracy: {acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c19529a-8ddb-43c0-ab3e-bf6bbb031111",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=\"XGBoost Run\"):\n",
    "\n",
    "    # Define and train the model\n",
    "    xgb_model = XGBClassifier(\n",
    "        objective=\"multi:softprob\",\n",
    "        num_class=3,\n",
    "        max_depth=3,\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric=\"mlogloss\"\n",
    "    )\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    # Predict and evaluate\n",
    "    predictions = xgb_model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions, average=\"macro\")\n",
    "    recall = recall_score(y_test, predictions, average=\"macro\")\n",
    "    f1 = f1_score(y_test, predictions, average=\"macro\")\n",
    "\n",
    "    # Log model parameters\n",
    "    mlflow.log_param(\"model_type\", \"XGBOOST\")\n",
    "    mlflow.log_param(\"max_depth\", 3)\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"learning_rate\", 0.1)\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "    mlflow.xgboost.log_model(xgb_model, \n",
    "                             artifact_path=\"xgb_model\",\n",
    "                             input_example=input_example,\n",
    "                             signature=signature,\n",
    "                            #  registered_model_name=\"main.dbdemos_iot_turbine.dbdemos_turbine_maintenance\"\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cac711a-a32d-474f-919d-6d9f29fcffc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>status</th>\n",
       "      <th>artifact_uri</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>metrics.recall</th>\n",
       "      <th>metrics.accuracy</th>\n",
       "      <th>metrics.precision</th>\n",
       "      <th>metrics.f1_score</th>\n",
       "      <th>params.model_type</th>\n",
       "      <th>params.n_estimators</th>\n",
       "      <th>params.max_depth</th>\n",
       "      <th>params.learning_rate</th>\n",
       "      <th>params.max_iter</th>\n",
       "      <th>tags.mlflow.databricks.cluster.info</th>\n",
       "      <th>tags.mlflow.databricks.gitRepoCommit</th>\n",
       "      <th>tags.mlflow.user</th>\n",
       "      <th>tags.mlflow.source.name</th>\n",
       "      <th>tags.mlflow.runName</th>\n",
       "      <th>tags.mlflow.runColor</th>\n",
       "      <th>tags.mlflow.databricks.notebook.commandID</th>\n",
       "      <th>tags.mlflow.databricks.gitRepoProvider</th>\n",
       "      <th>tags.mlflow.databricks.workspaceURL</th>\n",
       "      <th>tags.mlflow.databricks.gitRepoStatus</th>\n",
       "      <th>tags.mlflow.databricks.gitRepoRelativePath</th>\n",
       "      <th>tags.mlflow.log-model.history</th>\n",
       "      <th>tags.mlflow.databricks.cluster.libraries</th>\n",
       "      <th>tags.mlflow.databricks.cluster.id</th>\n",
       "      <th>tags.mlflow.databricks.gitRepoReferenceType</th>\n",
       "      <th>tags.mlflow.databricks.notebookID</th>\n",
       "      <th>tags.mlflow.databricks.notebookPath</th>\n",
       "      <th>tags.mlflow.databricks.workspaceID</th>\n",
       "      <th>tags.mlflow.databricks.gitRepoUrl</th>\n",
       "      <th>tags.mlflow.databricks.gitRepoReference</th>\n",
       "      <th>tags.mlflow.databricks.webappURL</th>\n",
       "      <th>tags.mlflow.source.type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5d4cc080ec414352806cef86432d7c44</td>\n",
       "      <td>01751c9c53794379b592485104bc6ab0</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>dbfs:/databricks/mlflow-tracking/01751c9c53794...</td>\n",
       "      <td>2025-08-09 15:45:23.954000+00:00</td>\n",
       "      <td>2025-08-09 15:45:31.312000+00:00</td>\n",
       "      <td>0.969357</td>\n",
       "      <td>0.979079</td>\n",
       "      <td>0.976699</td>\n",
       "      <td>0.972979</td>\n",
       "      <td>XGBOOST</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"cluster_name\":\"\",\"spark_version\":\"client.2.5...</td>\n",
       "      <td>2268011268b41a756fcf8b247f32353b11fb18bf</td>\n",
       "      <td>kemalcan@berkeley.edu</td>\n",
       "      <td>/Users/kemalcan@berkeley.edu/e2e-data-science/...</td>\n",
       "      <td>XGBoost Run</td>\n",
       "      <td>#da4c4c</td>\n",
       "      <td>1754754232754_8874398606133209524_ef18b40c8538...</td>\n",
       "      <td>gitHub</td>\n",
       "      <td>https://dbc-3a8de830-d6a2.cloud.databricks.com</td>\n",
       "      <td>unknown</td>\n",
       "      <td>lakehouse-iot-platform/04-Data-Science-ML/04.2...</td>\n",
       "      <td>[{\"artifact_path\":\"xgb_model\",\"flavors\":{\"pyth...</td>\n",
       "      <td>{\"installable\":[],\"redacted\":[]}</td>\n",
       "      <td>0809-154351-lgw1ydqn-v2n</td>\n",
       "      <td>branch</td>\n",
       "      <td>4368963137813901</td>\n",
       "      <td>/Users/kemalcan@berkeley.edu/e2e-data-science/...</td>\n",
       "      <td>4259139077557821</td>\n",
       "      <td>https://github.com/Berkeley-Data/e2e-data-scie...</td>\n",
       "      <td>final-student-version</td>\n",
       "      <td>https://dbc-3a8de830-d6a2.cloud.databricks.com</td>\n",
       "      <td>NOTEBOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8fe3da939ecc4683a6e71482fc91cc86</td>\n",
       "      <td>01751c9c53794379b592485104bc6ab0</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>dbfs:/databricks/mlflow-tracking/01751c9c53794...</td>\n",
       "      <td>2025-08-09 15:45:16.702000+00:00</td>\n",
       "      <td>2025-08-09 15:45:22.964000+00:00</td>\n",
       "      <td>0.947482</td>\n",
       "      <td>0.969317</td>\n",
       "      <td>0.970082</td>\n",
       "      <td>0.958351</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>{\"cluster_name\":\"\",\"spark_version\":\"client.2.5...</td>\n",
       "      <td>2268011268b41a756fcf8b247f32353b11fb18bf</td>\n",
       "      <td>kemalcan@berkeley.edu</td>\n",
       "      <td>/Users/kemalcan@berkeley.edu/e2e-data-science/...</td>\n",
       "      <td>Logistic Regression Run</td>\n",
       "      <td>#5387dd</td>\n",
       "      <td>1754754232754_7186461927566157459_ef18b40c8538...</td>\n",
       "      <td>gitHub</td>\n",
       "      <td>https://dbc-3a8de830-d6a2.cloud.databricks.com</td>\n",
       "      <td>unknown</td>\n",
       "      <td>lakehouse-iot-platform/04-Data-Science-ML/04.2...</td>\n",
       "      <td>[{\"artifact_path\":\"logreg_model\",\"flavors\":{\"p...</td>\n",
       "      <td>{\"installable\":[],\"redacted\":[]}</td>\n",
       "      <td>0809-154351-lgw1ydqn-v2n</td>\n",
       "      <td>branch</td>\n",
       "      <td>4368963137813901</td>\n",
       "      <td>/Users/kemalcan@berkeley.edu/e2e-data-science/...</td>\n",
       "      <td>4259139077557821</td>\n",
       "      <td>https://github.com/Berkeley-Data/e2e-data-scie...</td>\n",
       "      <td>final-student-version</td>\n",
       "      <td>https://dbc-3a8de830-d6a2.cloud.databricks.com</td>\n",
       "      <td>NOTEBOOK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id  ... tags.mlflow.source.type\n",
       "0  5d4cc080ec414352806cef86432d7c44  ...                NOTEBOOK\n",
       "1  8fe3da939ecc4683a6e71482fc91cc86  ...                NOTEBOOK\n",
       "\n",
       "[2 rows x 37 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.search_runs(order_by=['metrics.accuracy DESC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "097ad96e-6a02-4796-946a-81a4581223bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy:                   0.9790794979079498\nBest model type:                 XGBOOST\nBest model run id:                 5d4cc080ec414352806cef86432d7c44\n"
     ]
    }
   ],
   "source": [
    "best_run = pd.DataFrame(mlflow.search_runs(order_by=['metrics.accuracy DESC']).iloc[0])\n",
    "\n",
    "print(f\"Best accuracy:                   {best_run.loc['metrics.accuracy',0]}\")\n",
    "print(f\"Best model type:                 {best_run.loc['params.model_type',0]}\")\n",
    "\n",
    "best_model_run_id = best_run.loc['run_id',0]\n",
    "\n",
    "print(f\"Best model run id:                 {best_model_run_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ba437d4-ca23-41b3-96c3-7b007da1deeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now, we can test the best model. See if it is working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3b70bd7-a174-45e8-9689-6431d3903cb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "best_run = mlflow.search_runs(order_by=['metrics.accuracy DESC']).iloc[0]\n",
    "best_model_run_id = best_run['run_id']\n",
    "\n",
    "best_model_uri = f\"runs:/{best_model_run_id}/logreg_model\" if best_run['params.model_type'] == \"LogisticRegression\" else f\"runs:/{best_model_run_id}/xgb_model\"\n",
    "\n",
    "model_name = \"dbdemos_turbine_maintenance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19feab71-205d-49e5-9f1e-9e8bdc485fc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "mlflow.pyfunc.loaded_model:\n",
       "  artifact_path: xgb_model\n",
       "  flavor: mlflow.xgboost\n",
       "  run_id: 5d4cc080ec414352806cef86432d7c44"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Closing down clientserver connection\nINFO:py4j.clientserver:Closing down clientserver connection\nINFO:py4j.clientserver:Closing down clientserver connection\nINFO:py4j.clientserver:Closing down clientserver connection\n"
     ]
    }
   ],
   "source": [
    "loaded_model = mlflow.pyfunc.load_model(best_model_uri)\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec702667-8ef7-41d2-9df2-3375d32a324d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 3, 1, 0, 1, 1,\n",
       "       1, 1, 1, 3, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 2, 1, 1, 1, 3, 1, 3, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1,\n",
       "       1, 1, 0, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 1, 2, 1, 1, 1,\n",
       "       3, 1, 1, 3, 3, 1, 2, 1, 2, 1, 1, 3, 2, 1, 3, 1, 1, 1, 0, 1, 2, 1,\n",
       "       1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 3, 3, 1, 1, 1, 1, 0, 0, 3, 3, 2,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 3, 1, 1, 1, 2, 2, 3, 1, 2, 2, 1,\n",
       "       3, 1, 0, 3, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 3, 1,\n",
       "       3, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 3, 1, 2, 1, 0, 1,\n",
       "       3, 0, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1,\n",
       "       3, 1, 1, 1, 0, 0, 1, 1, 1, 1, 3, 1, 3, 1, 1, 1, 3, 1, 2, 1, 1, 3,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 3, 1, 1, 0, 1, 1, 1, 1, 2, 3, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 3, 1, 1, 1, 1, 3, 0, 1, 1, 3,\n",
       "       2, 1, 1, 1, 3, 1, 3, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 2, 3, 3,\n",
       "       1, 1, 1, 1, 0, 1, 0, 2, 1, 2, 1, 2, 1, 2, 1, 1, 3, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 3, 3, 1, 1, 2, 1, 1, 0, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 1, 1, 1, 1, 1, 0, 1, 3, 1, 1, 1, 3, 0, 1, 1, 1, 1, 1, 1, 2, 1,\n",
       "       0, 3, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 2, 1, 0, 0, 1,\n",
       "       2, 3, 1, 1, 1, 1, 1, 0, 1, 3, 2, 1, 0, 3, 1, 0, 1, 3, 2, 0, 1, 2,\n",
       "       1, 3, 1, 1, 0, 0, 3, 1, 1, 2, 3, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 3,\n",
       "       1, 1, 1, 3, 0, 1, 1, 1, 3, 1, 1, 0, 1, 1, 2, 0, 1, 1, 1, 2, 0, 1,\n",
       "       1, 1, 1, 3, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 2, 1, 3, 1, 1, 0, 2,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 2, 3, 1, 1, 3, 1, 1, 2, 1, 1, 1, 0, 3, 1,\n",
       "       0, 3, 1, 1, 1, 0, 1, 3, 2, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 0, 2, 0,\n",
       "       2, 0, 1, 1, 1, 1, 2, 1, 3, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 0, 2, 2,\n",
       "       1, 1, 3, 1, 1, 1, 3, 1, 1, 1, 1, 1, 2, 1, 3, 0, 0, 1, 1, 0, 2, 1,\n",
       "       1, 1, 1, 2, 1, 0, 0, 1, 1, 3, 2, 3, 3, 1, 1, 1, 1, 1, 3, 0, 3, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 3, 3, 3, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 3, 1, 1, 1, 0, 1, 1, 1, 3,\n",
       "       1, 1, 1, 3, 1, 3, 3, 1, 1, 1, 2, 0, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 3, 1, 2, 0, 1, 0, 2, 3, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 3,\n",
       "       0, 1, 2, 3, 2, 0, 1, 0, 3, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb533bbd-8815-4150-bebd-87bebd53af76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now we are satisfied with the model, we can register it in Unity Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8f05f40-211b-4cbf-a584-56d1200f56a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'main.dbdemos_iot_turbine.dbdemos_turbine_maintenance' already exists. Creating a new version of this model...\nCreated version '2' of model 'main.dbdemos_iot_turbine.dbdemos_turbine_maintenance'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "latest_model = mlflow.register_model(best_model_uri, f\"{catalog}.{db}.{model_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d276f063-05ad-4003-8e4f-d94735a6bc6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "If we're ready, we can move this model into Production stage in a click, or using the API. Let' register the model to Unity Catalog and move it to production.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44459c45-9d3c-43ca-8131-f95867ebe39c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    }
   ],
   "source": [
    "# Flag it as Production ready using UC Aliases\n",
    "MlflowClient().set_registered_model_alias(name=f\"{catalog}.{db}.dbdemos_turbine_maintenance\", \n",
    "                                          alias=\"prod\", \n",
    "                                          version=latest_model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9c3e849-7092-41d3-b72e-8ba0ca2ea0ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Closing down clientserver connection\nINFO:py4j.clientserver:Closing down clientserver connection\nINFO:py4j.clientserver:Closing down clientserver connection\nINFO:py4j.clientserver:Closing down clientserver connection\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "inputs: \n",
       "  ['avg_energy': double (required), 'std_sensor_A': double (required), 'std_sensor_B': double (required), 'std_sensor_C': double (required), 'std_sensor_D': double (required), 'std_sensor_E': double (required), 'std_sensor_F': double (required)]\n",
       "outputs: \n",
       "  [Tensor('int64', (-1,))]\n",
       "params: \n",
       "  None"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.pyfunc.load_model(f\"runs:/{best_model_run_id}/xgb_model\").metadata.signature\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8281987032933773,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "04.2-predictive_model_creation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
