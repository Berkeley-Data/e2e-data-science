{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "ed8876c9-27ae-4355-96fe-685a57d58395",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Generative AI with Databricks\n",
    "\n",
    "## From Predictive to Prescriptive Maintenance\n",
    "Manufacturers face labor shortages, supply chain disruptions, and rising costs, making efficient maintenance essential. Despite investments in maintenance programs, many struggle to boost asset productivity due to technician shortages and poor knowledge-sharing systems. This leads to knowledge loss and operational inefficiencies.\n",
    "\n",
    "<div style=\"font-family: 'DM Sans';\">\n",
    "  <div style=\"width: 400px; color: #1b3139; margin-left: 50px; margin-right: 50px; float: left;\">\n",
    "    <div style=\"color: #ff5f46; font-size:50px;\">73%</div>\n",
    "    <div style=\"font-size:25px; margin-top: -20px; line-height: 30px;\">\n",
    "      of manufacturers struggle to recruit maintenance technicians — McKinsey (2023)\n",
    "    </div>\n",
    "    <div style=\"color: #ff5f46; font-size:50px;\">55%</div>\n",
    "    <div style=\"font-size:25px; margin-top: -20px; line-height: 30px;\">\n",
    "      of manufacturers lack formal knowledge-sharing systems — McKinsey (2023)\n",
    "    </div>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "Generative AI can transform maintenance by reducing downtime and improving productivity. While predictive maintenance anticipates failures, Generative AI enables prescriptive maintenance. Using historical data, AI systems can identify issues, generate solutions, and assist technicians, allowing junior staff to perform effectively and freeing experts for complex tasks.\n",
    "<br><br>\n",
    "\n",
    "### From Models to Agent Systems\n",
    "Generative AI is moving from standalone models to modular agent systems ([Zaharia et al., 2024](https://bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/)). These systems integrate retrievers, models, prompts, and tools to handle complex tasks. Their modular design allows seamless upgrades (e.g., integrating a new LLM) and adaptation to changing needs.\n",
    "\n",
    "<br><br>\n",
    "<img style=\"float: right; margin-top: 10px;\" width=\"700px\" src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/refs/heads/main/images/manufacturing/lakehouse-iot-turbine/team_flow_liza.png\" />\n",
    "\n",
    "\n",
    "<br>\n",
    "<div style=\"font-size: 19px; margin-left: 0px; clear: left; padding-top: 10px; \">\n",
    "<img src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/refs/heads/main/images/liza.png\" style=\"float: left;\" width=\"80px\"> \n",
    "<h3 style=\"padding: 10px 0px 0px 5px;\">Liza, a Generative AI engineer, uses the Databricks Intelligence Platform to:</h3>\n",
    "<ul style=\"list-style: none; padding: 0; margin-left: 05%;\">\n",
    "  <li style=\"margin-bottom: 10px; display: flex; align-items: center;\">\n",
    "    <div class=\"badge\" style=\"height: 30px; width: 30px; border-radius: 50%; background: #fcba33; color: white; text-align: center; line-height: 30px; font-weight: bold; margin-right: 10px;\">1</div>\n",
    "    Build real-time data pipelines\n",
    "  </li>\n",
    "  <li style=\"margin-bottom: 10px; display: flex; align-items: center;\">\n",
    "    <div class=\"badge\" style=\"height: 30px; width: 30px; border-radius: 50%; background: #fcba33; color: white; text-align: center; line-height: 30px; font-weight: bold; margin-right: 10px;\">2</div>\n",
    "    Retrieve vectors & features\n",
    "  </li>\n",
    "  <li style=\"margin-bottom: 10px; display: flex; align-items: center;\">\n",
    "    <div class=\"badge\" style=\"height: 30px; width: 30px; border-radius: 50%; background: #fcba33; color: white; text-align: center; line-height: 30px; font-weight: bold; margin-right: 10px;\">3</div>\n",
    "    Create AI agent tools\n",
    "  </li>\n",
    "  <li style=\"margin-bottom: 10px; display: flex; align-items: center;\">\n",
    "    <div class=\"badge\" style=\"height: 30px; width: 30px; border-radius: 50%; background: #fcba33; color: white; text-align: center; line-height: 30px; font-weight: bold; margin-right: 10px;\">4</div>\n",
    "    Build & deploy agents\n",
    "  </li>\n",
    "  <li style=\"margin-bottom: 10px; display: flex; align-items: center;\">\n",
    "    <div class=\"badge\" style=\"height: 30px; width: 30px; border-radius: 50%; background: #fcba33; color: white; text-align: center; line-height: 30px; font-weight: bold; margin-right: 10px;\">5</div>\n",
    "    Operate in batch or real-time\n",
    "  </li>\n",
    "  <li style=\"display: flex; align-items: center;\">\n",
    "    <div class=\"badge\" style=\"height: 30px; width: 30px; border-radius: 50%; background: #fcba33; color: white; text-align: center; line-height: 30px; font-weight: bold; margin-right: 10px;\">6</div>\n",
    "    Evaluate agent performance\n",
    "  </li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "**Databricks empowers Liza with a Data + AI platform for Prescriptive Maintenance.** Let’s explore how to deploy this in production.\n",
    "\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=lakehouse&org_id=4003492105941350&notebook=%2F05-Generative-AI%2F05.1-ai-tools-iot-turbine-prescriptive-maintenance&demo_name=lakehouse-iot-platform&event=VIEW&path=%2F_dbdemos%2Flakehouse%2Flakehouse-iot-platform%2F05-Generative-AI%2F05.1-ai-tools-iot-turbine-prescriptive-maintenance&version=1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "59e1e932-8e37-4dfc-94da-1e699932eb5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Building Agent Systems with Databricks Mosaic AI agent framework\n",
    "\n",
    "We will build an Agent System designed to generate prescriptive work orders for wind turbine maintenance technicians. This system integrates multiple interacting components to ensure proactive and efficient maintenance, thereby optimizing the overall equipment effectiveness.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/refs/heads/main/images/manufacturing/lakehouse-iot-turbine/iot_agent_graph_v2_0.png\" style=\"margin-left: 5px; float: right\"  width=\"1000px;\">\n",
    "\n",
    "Databricks simplifies this by providing a built-in service to:\n",
    "\n",
    "- Create and store your AI tools leveraging UC functions\n",
    "- Execute the AI tools in a safe way\n",
    "- Use agents to reason about the tools you selected and chain them together to properly answer your question. \n",
    "\n",
    "\n",
    "This notebook creates the three Mosaic AI tools and associated Mosaic AI endpoints, which will be composed together into a agent in notebook [05.2-agent-creation-guide]($./05.2-agent-creation-guide).\n",
    "1. **Turbine predictor** which uses a Model Serving endpoint to predict turbines at risk of failure.\n",
    "2. **Turbine specifications retriever** which retrieve the turbine specifications based on its id.\n",
    "3. **Turbine maintenance guide**  which uses a Vector Search endpoint to retrieve maintenance guide based on the turbines and issues being adressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6760fd38-9a07-4df9-a04d-63e3b975e9ae",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install required external libraries"
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-vectorsearch==0.49 databricks-feature-engineering==0.8.0 databricks-sdk==0.40.0 \n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8edbbc63-4184-4f4f-9a32-631fc0387c0e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Initializing the Application"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run ../_resources/00-setup $reset_all_data=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dac142d0-6b92-412c-849a-e55d562d8790",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DROP FUNCTION IF EXISTS turbine_specifications_retriever;\n",
    "\n",
    "--turbine_specifications_retriever to get the current status of a turbine\n",
    "--This function is used to retrieve the turbine specifications based on its id\n",
    "\n",
    "CREATE OR REPLACE FUNCTION \n",
    "turbine_specifications_retriever(turbine_id STRING COMMENT 'ID of the wind turbine to look up')\n",
    "RETURNS TABLE (\n",
    "  avg_energy DOUBLE COMMENT 'Average energy reading',\n",
    "  std_sensor_A DOUBLE COMMENT 'Sensor A reading',\n",
    "  std_sensor_B DOUBLE COMMENT 'Sensor B reading',\n",
    "  std_sensor_C DOUBLE COMMENT 'Sensor C reading',\n",
    "  std_sensor_D DOUBLE COMMENT 'Sensor D reading',\n",
    "  std_sensor_E DOUBLE COMMENT 'Sensor E reading',\n",
    "  std_sensor_F DOUBLE COMMENT 'Sensor F reading'\n",
    ")\n",
    "LANGUAGE SQL\n",
    "COMMENT 'This function retrieves the turbine sensor readings / specifications based on the turbine_id'\n",
    "RETURN\n",
    "(\n",
    "SELECT \n",
    "\n",
    "avg_energy, std_sensor_A, std_sensor_B, std_sensor_C, std_sensor_D, std_sensor_E, std_sensor_F\n",
    "FROM main.dbdemos_iot_turbine.turbine_current_features\n",
    "WHERE turbine_id = turbine_specifications_retriever.turbine_id\n",
    "SORT BY hourly_timestamp DESC\n",
    "limit 1\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0a8eb73-5828-4bfe-ab98-c1f83c727102",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1753544700778}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM turbine_specifications_retriever('004a641f-e9e5-9fff-d421-1bf88319420b')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "fd9c59e1-2893-43cd-83cd-d4599c908242",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Part 1: Create the Turbine Predictor as a tool to predict turbine failure\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/refs/heads/main/images/manufacturing/lakehouse-iot-turbine/iot_agent_graph_v2_1.png\" style=\"float: right; width: 600px; margin-left: 10px\">\n",
    "\n",
    "To enable our Agent System to predict turbine failtures based on industrial IoT sensor readings, we will rely on the model we deployed previously in the  [./04.3-running-inference-iot-turbine]($./04.3-running-inference-iot-turbine) notebook. \n",
    "\n",
    "**Make sure you run this ML notebook to create the model serving endpoint!**\n",
    "\n",
    "\n",
    "### Using the Model Serving as tool to predict faulty turbines\n",
    "Let's define the turbine predictor tool function our LLM agent will be able to execute. \n",
    "\n",
    "AI agents use [AI Agent Tools](https://docs.databricks.com/en/generative-ai/create-log-agent.html#create-ai-agent-tools) to perform actions besides language generation, for example to retrieve structured or unstructured data, execute code, or talk to remote services (e.g. send an email or Slack message). \n",
    "\n",
    "These functions can contain any logic, from simple SQL to advanced python. Below we wrap the model serving endpoint in a SQL function using '[ai_query function](https://docs.databricks.com/en/sql/language-manual/functions/ai_query.html)'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e6efa4b-1c63-4ba9-b6a7-9cc811e8e13d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DROP FUNCTION IF EXISTS turbine_maintenance_predictor;\n",
    "\n",
    "CREATE OR REPLACE FUNCTION \n",
    "turbine_maintenance_predictor(\n",
    "    sensor_values ARRAY<DOUBLE> COMMENT 'Array of 7 double values (energy and sensor readings) from a wind turbine. Example: array(avg_energy, std_sensor_A, std_sensor_B, std_sensor_C, std_sensor_D, std_sensor_E, std_sensor_F)'\n",
    "    )\n",
    "RETURNS STRING\n",
    "LANGUAGE SQL\n",
    "COMMENT 'This tool predicts whether or not a turbine is faulty to facilitate proactive maintenance. It expects an array of 7 double values (energy and sensor readings) as input and returns a string indicating if a particular sensor is predicted to be faulty or if all sensors are ok.'\n",
    "RETURN\n",
    "(\n",
    "    SELECT CASE \n",
    "        -- Convert the prediction to a string that can be understood by the agent based on the output of the AI query\n",
    "        WHEN prediction = '0.0' THEN 'Sensor F fault'\n",
    "        WHEN prediction = '1.0' THEN 'ok' \n",
    "        WHEN prediction = '2.0' THEN 'Sensor B fault' \n",
    "        WHEN prediction = '3.0' THEN 'Sensor D fault'\n",
    "        ELSE 'faulty'\n",
    "        END AS prediction\n",
    "    FROM (    \n",
    "        SELECT ai_query(\n",
    "            'dbdemos_iot_turbine_prediction_endpoint', \n",
    "            sensor_values,\n",
    "            'DOUBLE'\n",
    "        ) as prediction\n",
    "    )    \n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2295789d-121e-48fb-900a-6474329e1b64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# DROP FUNCTION IF EXISTS turbine_maintenance_predictor;\n",
    "\n",
    "# CREATE OR REPLACE FUNCTION \n",
    "\n",
    "# turbine_maintenance_predictor(\n",
    "#     sensor_values ARRAY<DOUBLE>\n",
    "#     )\n",
    "# RETURNS STRING\n",
    "# LANGUAGE SQL\n",
    "# COMMENT 'This tool predicts whether or not a turbine is faulty to facilitate proactive maintenance. It expects an array of 7 double values (energy and sensor readings) as input and returns a string'\n",
    "# RETURN\n",
    "# (\n",
    "#     SELECT ai_query(\n",
    "#         'dbdemos_iot_turbine_prediction_endpoint', \n",
    "        \n",
    "#         array(\n",
    "#             sensor_values[0],\n",
    "#             sensor_values[1],\n",
    "#             sensor_values[2],\n",
    "#             sensor_values[3],\n",
    "#             sensor_values[4],\n",
    "#             sensor_values[5],\n",
    "#             sensor_values[6]\n",
    "#             ),\n",
    "#         'DOUBLE'\n",
    "#     )\n",
    "# );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54cb0433-fd24-494e-88a3-62f2c101e0bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# -- for testing purposes only\n",
    "# DROP FUNCTION IF EXISTS get_dummy_sensor_value_readings;\n",
    "\n",
    "# CREATE OR REPLACE FUNCTION get_dummy_sensor_value_readings()\n",
    "# RETURNS ARRAY<DOUBLE>\n",
    "# LANGUAGE SQL\n",
    "# COMMENT 'Returns an array of 7 random double values simulating sensor readings'\n",
    "# RETURN (\n",
    "#   array(\n",
    "#     rand(), \n",
    "#     rand(), \n",
    "#     rand(), \n",
    "#     rand(), \n",
    "#     rand(), \n",
    "#     rand(), \n",
    "#     rand()\n",
    "#   )\n",
    "# );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf474cf0-01c1-4be3-a642-32afd814d1a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df = spark.sql(\"SELECT get_dummy_sensor_value_readings() AS sensor_values\")\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a11dc8a-f5df-45ee-90c5-dfc0b82275d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Agent should call turbine_specifications_retriever() to get sensor readings, then agent needs to format readings as an array and call turbine_maintenance_predictor() to get a prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2bf7899d-7d02-4034-a7dd-3d2e1211fb52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now we can test out our function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3017fc78-ce21-443b-9169-ddf5b050a4cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- test our prediction function\n",
    "SELECT turbine_maintenance_predictor(\n",
    "    array(\n",
    "      0.9000803742589635,                           -- avg_energy\n",
    "      2.2081154200781867,                           -- std_sensor_A\n",
    "      2.6012126574143823,                           -- std_sensor_B\n",
    "      2.1075958066966423,                           -- std_sensor_C\n",
    "      2.2081154200781867,                           -- std_sensor_D\n",
    "      2.6012126574143823,                           -- std_sensor_E\n",
    "      2.1075958066966423                            -- std_sensor_F\n",
    "    )  \n",
    ") AS prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "8ca12188-e739-4226-bddc-3f1a4b6485f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Part 3: Add a tool to access our maintenance guide content and provide support to the operator during maintenance operation\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/refs/heads/main/images/manufacturing/lakehouse-iot-turbine/iot_agent_graph_v2_3.png\" style=\"float: right; width: 600px; margin-left: 10px\">\n",
    "\n",
    "\n",
    "We were provided with PDF guide containing all the error code and maintenance steps for the critical components of our wind turbine. The're saved as pdf file in our volume.\n",
    "\n",
    "Let's parse them and index them so that we can properly retrieve them. We'll save them in a Vector Search endpoint and leverage it to guide the operators with the maintenance step and recommendations.\n",
    "\n",
    "We'll use a Managed embedding index to make it simple. In this section we will:\n",
    "\n",
    "1. Parse and save our PDF text in a Delta Table using Databricks AI Query `ai_parse_document`\n",
    "2. Create a `Vector Search endpoint` (required to host your vector search index)\n",
    "3. Create a `Vector Search Direct Index`  (the actual index)\n",
    "4. Create a `Tool (UC function)` using our vector search "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1732888c-4571-469b-925b-88a471a5cb84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### 2.1. Parse and save our PDF text\n",
    "Let's start by parsing the maintenance guide documents, saved as pdf in our volume:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0914421b-8289-4917-8a78-418e27cbc52b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DROP TABLE IF EXISTS turbine_maintenance_guide;\n",
    "\n",
    "CREATE TABLE turbine_maintenance_guide (\n",
    "  id BIGINT GENERATED ALWAYS AS IDENTITY,\n",
    "  EAN STRING,\n",
    "  weight STRING,\n",
    "  component_type STRING,\n",
    "  component_name STRING,\n",
    "  full_guide STRING)\n",
    "  TBLPROPERTIES (delta.enableChangeDataFeed = true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af4fd257-c291-4892-9d11-e6d9b4be1166",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_selected = spark.read.option(\"header\", \"true\").csv(\"/Volumes/main/dbdemos_iot_turbine/additional_data/pdf_to_structured.csv\").select(\"EAN\", \"weight\", \"component_type\", \"component_name\", \"full_guide\").na.drop(how=\"all\")\n",
    "\n",
    "# df_selected.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"main.dbdemos_iot_turbine.turbine_maintenance_guide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe427989-e829-40da-863b-0eead80b2043",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1753475700219}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "INSERT INTO turbine_maintenance_guide (EAN, weight, component_type, component_name, full_guide)\n",
    "\n",
    "SELECT ai_query(\n",
    "    'databricks-gemma-3-12b',\n",
    "    CONCAT(\"Extract the EAN from the following text. Return only the EAN. \\n\\nText:\", full_guide)    -- Placeholder for the prompt and input\n",
    "    ) AS EAN  -- Placeholder for the output column\n",
    "    ,ai_query(\n",
    "    'databricks-gemma-3-12b',\n",
    "    CONCAT(\"Extract the component weight from the following text. Return only the component weight. \\n\\nText:\", full_guide)    -- Placeholder for the prompt and input\n",
    "    ) AS weight  -- Placeholder for the output column\n",
    "    ,ai_query(\n",
    "    'databricks-gemma-3-12b',\n",
    "    CONCAT(\"Extract the component type from the following text. Return only the component type. \\n\\nText:\", full_guide)    -- Placeholder for the prompt and input\n",
    "    ) AS component_type  -- Placeholder for the output column \n",
    "    ,ai_query(\n",
    "    'databricks-gemma-3-12b',\n",
    "    CONCAT(\"Extract the component name from the following text. Return only the component name. \\n\\nText:\", full_guide)    -- Placeholder for the prompt and input\n",
    "    ) AS component_name  -- Placeholder for the output column\n",
    "    ,full_guide \n",
    "FROM (\n",
    "    -- Combine the content of all pages into a single string separated by new lines\n",
    "    SELECT array_join(\n",
    "\n",
    "            -- Transform each page struct in the array to just its 'content' field (extract text from each page)\n",
    "            transform(\n",
    "              parsed_document:document.pages::ARRAY<STRUCT<content:STRING>>, -- Array of page structs from the parsed document\n",
    "              x -> x.content -- For each struct (page), extract the 'content' string\n",
    "             ), \n",
    "             \n",
    "             '\\n' -- Join all extracted page contents with a newline character as the separator\n",
    "             ) \n",
    "             \n",
    "             AS full_guide\n",
    "    FROM (\n",
    "      -- Parse the document content\n",
    "      SELECT ai_parse_document(content) AS parsed_document\n",
    "      FROM READ_FILES(\"/Volumes/main/dbdemos_iot_turbine/turbine_raw_landing/maintenance_guide\", format => 'binaryFile')\n",
    "    )\n",
    ");\n",
    "\n",
    "SELECT * FROM turbine_maintenance_guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "485d17d8-caf6-4c39-b76a-05aa901270e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.2. Creating the Vector Search endpoint\n",
    "\n",
    "Let's create a new Vector search endpoint. You can also use the [UI under Compute](#/setting/clusters/vector-search) to directly create your endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c53199e-8cd3-4e52-b667-5e6954b92bbd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Creating the Vector Search endpoint"
    }
   },
   "outputs": [],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "vsc = VectorSearchClient(disable_notice=True)\n",
    "\n",
    "if not endpoint_exists(vsc, VECTOR_SEARCH_ENDPOINT_NAME):\n",
    "    vsc.create_endpoint(name=VECTOR_SEARCH_ENDPOINT_NAME, \n",
    "                        endpoint_type=\"STANDARD\")\n",
    "\n",
    "wait_for_vs_endpoint_to_be_ready(vsc, \n",
    "                                 VECTOR_SEARCH_ENDPOINT_NAME)\n",
    "\n",
    "\n",
    "print(f\"Endpoint named {VECTOR_SEARCH_ENDPOINT_NAME} is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "f2cb98b0-7524-4527-8ea4-c1ae678ffda7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### 2.3 Creating the Vector Search Index\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/index_creation.gif?raw=true\" width=\"600px\" style=\"float: right; margin-left: 10px\">\n",
    "\n",
    "You can view your endpoint on the [Vector Search Endpoints UI](#/setting/clusters/vector-search). Click on the endpoint name to see all indexes that are served by the endpoint.\n",
    "\n",
    "All we now have to do is to as Databricks to create the index on top of our table. The Delta Table will automatically be synched with the index.\n",
    "\n",
    "\n",
    "Again, you can do that using your Unity Catalog UI, and selecting the turbine_maintenance_guide table in your Unity Catalog, and click on add a vector search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75fa4683-3aec-42ed-ae97-83d56bbd5790",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Creating the VS from the maintenance table"
    }
   },
   "outputs": [],
   "source": [
    "import databricks.sdk.service.catalog as c\n",
    "\n",
    "# Where we want to store our index\n",
    "vs_index_fullname = f\"{catalog}.{db}.turbine_maintenance_guide_vs_index\"\n",
    "\n",
    "if not index_exists(vsc, VECTOR_SEARCH_ENDPOINT_NAME, vs_index_fullname):\n",
    "  print(f\"Creating index {vs_index_fullname} on endpoint {VECTOR_SEARCH_ENDPOINT_NAME}...\")\n",
    "  \n",
    "  index = vsc.create_delta_sync_index(\n",
    "    endpoint_name=VECTOR_SEARCH_ENDPOINT_NAME,\n",
    "    source_table_name=f\"{catalog}.{db}.turbine_maintenance_guide\",\n",
    "    index_name=vs_index_fullname,\n",
    "    pipeline_type=\"TRIGGERED\",\n",
    "    primary_key='id',\n",
    "    embedding_source_column=\"full_guide\",\n",
    "    embedding_model_endpoint_name=\"databricks-gte-large-en\"\n",
    "  )\n",
    "else:\n",
    "  print(f\"Grabbing existing index {vs_index_fullname} on endpoint {VECTOR_SEARCH_ENDPOINT_NAME}...\")\n",
    "  index = vsc.get_index(VECTOR_SEARCH_ENDPOINT_NAME, vs_index_fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d95969b7-5740-481c-93e0-fb3bbbf481b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "exists = index_exists(vsc, VECTOR_SEARCH_ENDPOINT_NAME, vs_index_fullname)\n",
    "display(spark.createDataFrame([(vs_index_fullname, exists)], [\"index_name\", \"exists\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "01310d1f-28fb-4aeb-8f84-b11ccb15eab9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.4 Create our tool\n",
    "Below, we utilize the _VECTOR\\_SEARCH_ SQL function from Databricks to easily set up our maintenance reports retriever function. Our agent will utilize this function in the subsequent steps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95418fdd-74b7-43e7-95ed-540d1818ff40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"DROP FUNCTION IF EXISTS turbine_maintenance_guide_retriever\")\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION \n",
    "turbine_maintenance_guide_retriever(question STRING COMMENT 'Question to be answered from the turbine maintenance guides.')\n",
    "RETURNS ARRAY<STRING>\n",
    "LANGUAGE SQL\n",
    "COMMENT 'This tool searches / retrieves the wind turbine maintenance guide for a given question'\n",
    "RETURN (\n",
    "  SELECT collect_list(full_guide) \n",
    "  FROM VECTOR_SEARCH(index => '{catalog}.{schema}.turbine_maintenance_guide_vs_index', query => question, num_results => 1) ) \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdbce0ab-1b1b-4026-8a44-a959be479ab6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "-- Let's test the tool we created\n",
    "SELECT turbine_maintenance_guide_retriever('The VibeGuard TVS-950 is giving me an error code TVS-001.') AS reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a6c9473-c398-4a3c-89ee-b109c1823267",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Exploring Mosaic AI Tools in Unity Catalog\n",
    "\n",
    "Our tools are ready! \n",
    "\n",
    "You can now view the UC function tools in Catalog Explorer. Click **Catalog** in the sidebar. In the Catalog Explorer, navigate to your catalog and schema. \n",
    "\n",
    "The UC function tools appears under **Functions**. \n",
    "\n",
    "<img src=\"https://github.com/Datastohne/demo/blob/main/Screenshot%202024-09-18%20at%2016.24.24.png?raw=true\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ba13523-10c5-4685-90fc-237ef613ca63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "132daa16-0fcf-44b3-b00f-2d667714128c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %pip install --quiet openmeteo-requests\n",
    "# %pip install --quiet requests-cache retry-requests numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9aeb0d8e-5bcf-4963-8bde-3759bab0243a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import openmeteo_requests\n",
    "\n",
    "# import pandas as pd\n",
    "# import requests_cache\n",
    "# from retry_requests import retry\n",
    "\n",
    "# # Setup the Open-Meteo API client with cache and retry on error\n",
    "# cache_session = requests_cache.CachedSession('.cache', expire_after = 3600)\n",
    "# retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "# openmeteo = openmeteo_requests.Client(session = retry_session)\n",
    "\n",
    "# # Make sure all required weather variables are listed here\n",
    "# # The order of variables in hourly or daily is important to assign them correctly below\n",
    "# url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "# params = {\n",
    "# \t\"latitude\": 52.52,\n",
    "# \t\"longitude\": 13.41,\n",
    "# \t\"hourly\": \"temperature_2m\"\n",
    "# }\n",
    "# responses = openmeteo.weather_api(url, params=params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e98df57-c2ef-4aa5-acf1-4f637f760c70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## What’s next: test your Agents with Databricks Playground\n",
    "\n",
    "Now that we have our AI Tools ready and registered in Unity Catalog, we can compose them into an agent system that generates maintenance work orders using the Mosaic AI agent framework.\n",
    "\n",
    "Open the [05.2-agent-creation-guide]($./05.2-agent-creation-guide) notebook to create and deploy the system."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8740357028112988,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "05.1-ai-tools-iot-turbine-prescriptive-maintenance",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
