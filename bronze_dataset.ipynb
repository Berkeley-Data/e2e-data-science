{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "519f4916-e466-421b-a19d-5239888bab03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install --quiet databricks-dlt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c011d6c1-fce3-45b9-8580-c5c8ea134434",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b70b2243-68ee-41af-a210-9d9be749fec0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d1641b2-c9ae-4b6e-b0b5-5aca61d25add",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "I received the following Exception.\n",
    "\n",
    "Exception: This is a stub that only contains the interfaces to Delta Live Tables. Delta Live Tables pipelines cannot be run locally. To learn more,  see https://docs.databricks.com/en/delta-live-tables/develop-locally.html. If you would like to run your code for testing purposes, you can switch this error message off by calling enable_local_execution() before running your pipeline code.\n",
    "\n",
    "That's why I am running dlt.enable_local_execution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "726b94af-5404-45d2-9a05-dee8875d8bad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dlt.enable_local_execution()\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"turbine_bronze\",\n",
    "    comment=\"Turbine details, with location, wind turbine model type etc\"\n",
    ")\n",
    "def turbine_bronze():\n",
    "    return (\n",
    "        spark.readStream.format(\"cloudFiles\")\n",
    "        .option(\"cloudFiles.format\", \"json\")\n",
    "        .option(\"cloudFiles.inferColumnTypes\", \"true\")\n",
    "        .load(\"/Volumes/main/dbdemos_iot_turbine/turbine_raw_landing/turbine\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e620aaa7-91a8-4379-9ef8-1e692332c091",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "@dlt.table(\n",
    "    name=\"sensor_bronze\",\n",
    "    comment=\"Raw sensor data coming from json files ingested in incremental with Auto Loader: vibration, energy produced etc. 1 point every X sec per sensor.\"\n",
    ")\n",
    "def sensor_bronze():\n",
    "    return (\n",
    "        spark.readStream.format(\"cloudFiles\")\n",
    "        .option(\"cloudFiles.format\", \"json\")\n",
    "        .option(\"cloudFiles.inferColumnTypes\", \"true\")\n",
    "        .load(\"/Volumes/main/dbdemos_iot_turbine/turbine_raw_landing/incoming_data\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54c6681e-852e-4da2-af4f-822f8c8b01c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"maintenance_guide_bronze\",\n",
    "    comment=\"Raw maintenance guide data ingested from PDF files\"\n",
    ")\n",
    "def maintenance_guide_bronze():\n",
    "    return (\n",
    "        spark.readStream.format(\"cloudFiles\")\n",
    "        .option(\"cloudFiles.format\", \"binaryFile\")\n",
    "        .option(\"cloudFiles.inferColumnTypes\", \"true\")\n",
    "        .load(\"/Volumes/main/dbdemos_iot_turbine/turbine_raw_landing/maintenance_guide\")\n",
    "        .filter(\"path LIKE '%.pdf'\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6ed0829-6b8f-46e7-9a65-688b9af3bce3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"parts_bronze\",\n",
    "    comment=\"Parts data from json files ingested in incremental with Auto Loader\"\n",
    ")\n",
    "def parts_bronze():\n",
    "    return (\n",
    "        spark.readStream.format(\"cloudFiles\")\n",
    "        .option(\"cloudFiles.format\", \"json\")\n",
    "        .option(\"cloudFiles.inferColumnTypes\", \"true\")\n",
    "        .load(\"/Volumes/main/dbdemos_iot_turbine/turbine_raw_landing/parts\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19b57767-0a8e-4b03-b6bf-3645bf421aa9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"historical_turbine_bronze\",\n",
    "    comment=\"Historical turbine data from json files ingested in incremental with Auto Loader\"\n",
    ")\n",
    "def historical_turbine_bronze():\n",
    "    return (\n",
    "        spark.readStream.format(\"cloudFiles\")\n",
    "        .option(\"cloudFiles.format\", \"json\")\n",
    "        .option(\"cloudFiles.inferColumnTypes\", \"true\")\n",
    "        .load(\"/Volumes/main/dbdemos_iot_turbine/turbine_raw_landing/historical_turbine_status\")\n",
    "        .filter(\"path LIKE '%.json'\")\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze_dataset",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
